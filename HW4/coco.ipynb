{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from coco_dataloader import COCO_loader\n",
    "\n",
    "# cl = COCO_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HW4Net1, HW4Net2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all images containing given categories, select one at random\n",
    "# categories = ['airplane', 'bus', 'cat', 'dog', 'pizza']\n",
    "\n",
    "# # def get_plots(image_list):\n",
    "# data_path = '/mnt/cloudNAS4/akshita/Documents/datasets/coco_custom'\n",
    "# num_images = 3\n",
    "# all_images = []\n",
    "# for category in categories:\n",
    "#     cat_images = []\n",
    "#     path = os.path.join(data_path, category, 'train')\n",
    "#     image_list = os.listdir(path)[:num_images]\n",
    "#     # print(image_list)\n",
    "#     for img in image_list:\n",
    "#         img = cv2.imread(os.path.join(path, img))\n",
    "#         cat_images.append(img)\n",
    "#     tot_images = np.concatenate(cat_images, axis=1)\n",
    "\n",
    "#     all_images.append(tot_images)\n",
    "\n",
    "# all_images = np.concatenate(all_images, axis=0)\n",
    "\n",
    "# cv2.imwrite(\"results/sampled_images.png\", all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 1, batch:   100] loss: 1.369\n",
      "[epoch]: 1, batch:   200] loss: 1.154\n",
      "[epoch]: 1, batch:   300] loss: 1.090\n",
      "[epoch]: 1, batch:   400] loss: 1.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:07, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 2, batch:   100] loss: 0.938\n",
      "[epoch]: 2, batch:   200] loss: 0.966\n",
      "[epoch]: 2, batch:   300] loss: 0.918\n",
      "[epoch]: 2, batch:   400] loss: 0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:28<01:53, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 3, batch:   100] loss: 0.837\n",
      "[epoch]: 3, batch:   200] loss: 0.860\n",
      "[epoch]: 3, batch:   300] loss: 0.820\n",
      "[epoch]: 3, batch:   400] loss: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:42<01:39, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 4, batch:   100] loss: 0.722\n",
      "[epoch]: 4, batch:   200] loss: 0.728\n",
      "[epoch]: 4, batch:   300] loss: 0.753\n",
      "[epoch]: 4, batch:   400] loss: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:57<01:26, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 5, batch:   100] loss: 0.580\n",
      "[epoch]: 5, batch:   200] loss: 0.607\n",
      "[epoch]: 5, batch:   300] loss: 0.611\n",
      "[epoch]: 5, batch:   400] loss: 0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:14<01:16, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 6, batch:   100] loss: 0.480\n",
      "[epoch]: 6, batch:   200] loss: 0.431\n",
      "[epoch]: 6, batch:   300] loss: 0.500\n",
      "[epoch]: 6, batch:   400] loss: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:30<01:02, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 7, batch:   100] loss: 0.319\n",
      "[epoch]: 7, batch:   200] loss: 0.351\n",
      "[epoch]: 7, batch:   300] loss: 0.428\n",
      "[epoch]: 7, batch:   400] loss: 0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:46<00:47, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 8, batch:   100] loss: 0.242\n",
      "[epoch]: 8, batch:   200] loss: 0.283\n",
      "[epoch]: 8, batch:   300] loss: 0.301\n",
      "[epoch]: 8, batch:   400] loss: 0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:01<00:31, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 9, batch:   100] loss: 0.183\n",
      "[epoch]: 9, batch:   200] loss: 0.249\n",
      "[epoch]: 9, batch:   300] loss: 0.254\n",
      "[epoch]: 9, batch:   400] loss: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:17<00:15, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 10, batch:   100] loss: 0.136\n",
      "[epoch]: 10, batch:   200] loss: 0.208\n",
      "[epoch]: 10, batch:   300] loss: 0.194\n",
      "[epoch]: 10, batch:   400] loss: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:32<00:00, 15.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from dataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(60146)\n",
    "\n",
    "categories = ['airplane', 'bus', 'cat', 'dog', 'pizza']\n",
    "data_path = '/mnt/cloudNAS4/akshita/Documents/datasets/coco_custom'\n",
    "train_dataset = MyDataset(root=data_path, categories=categories, split='train')\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def train(net, train_dataloader, epochs=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() == True else 'cpu'\n",
    "    net.train()\n",
    "    net = net.to(device=device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "    tot_loss = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i+1)% 100 == 0:\n",
    "                print(\"[epoch]: %d, batch: %5d] loss: %.3f\" %(epoch+1, i+1, running_loss / 100))\n",
    "                tot_loss.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "    return tot_loss\n",
    "\n",
    "net = HW4Net1()\n",
    "loss_1 = train(net=net, train_dataloader=train_dataloader, epochs=10)\n",
    "torch.save(net.state_dict(), 'HW4/results/net1.pt')\n",
    "# np.save('first_net.npy', np.array(loss_1), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 1, batch:   100] loss: 1.378\n",
      "[epoch]: 1, batch:   200] loss: 1.130\n",
      "[epoch]: 1, batch:   300] loss: 1.090\n",
      "[epoch]: 1, batch:   400] loss: 1.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:16<02:29, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 2, batch:   100] loss: 0.994\n",
      "[epoch]: 2, batch:   200] loss: 0.954\n",
      "[epoch]: 2, batch:   300] loss: 0.958\n",
      "[epoch]: 2, batch:   400] loss: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:36<02:29, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 3, batch:   100] loss: 0.868\n",
      "[epoch]: 3, batch:   200] loss: 0.869\n",
      "[epoch]: 3, batch:   300] loss: 0.815\n",
      "[epoch]: 3, batch:   400] loss: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:59<02:22, 20.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 4, batch:   100] loss: 0.775\n",
      "[epoch]: 4, batch:   200] loss: 0.744\n",
      "[epoch]: 4, batch:   300] loss: 0.738\n",
      "[epoch]: 4, batch:   400] loss: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:20<02:04, 20.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 5, batch:   100] loss: 0.612\n",
      "[epoch]: 5, batch:   200] loss: 0.642\n",
      "[epoch]: 5, batch:   300] loss: 0.632\n",
      "[epoch]: 5, batch:   400] loss: 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:45<01:51, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 6, batch:   100] loss: 0.490\n",
      "[epoch]: 6, batch:   200] loss: 0.497\n",
      "[epoch]: 6, batch:   300] loss: 0.546\n",
      "[epoch]: 6, batch:   400] loss: 0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:09<01:30, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 7, batch:   100] loss: 0.411\n",
      "[epoch]: 7, batch:   200] loss: 0.374\n",
      "[epoch]: 7, batch:   300] loss: 0.413\n",
      "[epoch]: 7, batch:   400] loss: 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:32<01:08, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 8, batch:   100] loss: 0.271\n",
      "[epoch]: 8, batch:   200] loss: 0.315\n",
      "[epoch]: 8, batch:   300] loss: 0.335\n",
      "[epoch]: 8, batch:   400] loss: 0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:55<00:46, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 9, batch:   100] loss: 0.190\n",
      "[epoch]: 9, batch:   200] loss: 0.232\n",
      "[epoch]: 9, batch:   300] loss: 0.254\n",
      "[epoch]: 9, batch:   400] loss: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:19<00:23, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch]: 10, batch:   100] loss: 0.127\n",
      "[epoch]: 10, batch:   200] loss: 0.176\n",
      "[epoch]: 10, batch:   300] loss: 0.232\n"
     ]
    }
   ],
   "source": [
    "net = HW4Net2()\n",
    "loss_2 = train(net=net, train_dataloader=train_dataloader, epochs=10)\n",
    "torch.save(net.state_dict(), 'HW4/results/net2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('first_net.npy', np.array(loss_1), allow_pickle=True)\n",
    "np.save('second_net.npy', np.array(loss_2), allow_pickle=True)\n",
    "\n",
    "# b = np.load('a.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_1, label='Net1')\n",
    "plt.plot(loss_2, label='Net2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Input: (B, C_{in}, H_{in}, W_{in})$ \n",
    "\n",
    "$Output: (B, C_{out}, H_{out}, W_{out})$\n",
    "\n",
    "$$H_{out} = floor\\left( \\frac{H_{in} + 2\\times pad[0] - dilation[0] \\times (kernel - 1) -1 }{stride[0]} +1 \\right)$$\n",
    "$$W_{out} = floor\\left( \\frac{W_{in} + 2\\times pad[1] - dilation[1] \\times (kernel - 1) -1 }{stride[1]} +1 \\right)$$\n",
    "\n",
    "In *Net1*, ```dilation``` and ```stride``` are set to default values, i.e., both 1 and ```pad = 0``` . Above equations are transformed to:\n",
    "\n",
    "$$H_{out} = floor\\left( H_{in} - kernel + 1 \\right)$$\n",
    "$$W_{out} = floor\\left( W_{in} - kernel + 1 \\right)$$\n",
    "\n",
    "In *Net2*, ```dilation``` and ```stride``` are set to default values, i.e., both 1 and ```pad = 1``` . Above equations are transformed to:\n",
    "\n",
    "$$H_{out} = floor\\left( H_{in} + 2 - kernel + 1 \\right) = floor\\left( H_{in}  - kernel + 3 \\right)$$\n",
    "$$W_{out} = floor\\left( W_{in} + 2 - kernel + 1 \\right) = floor\\left( W_{in}  - kernel + 3 \\right)$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f680f4d97cf514679e00d4da1d9b5ffad508e5bcade52d18cdbe0b82edcbe4b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
