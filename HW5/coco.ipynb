{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.22s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2791/2791 [01:18<00:00, 35.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2818/2818 [01:20<00:00, 34.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2202/2202 [00:10<00:00, 204.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "loading annotations into memory...\n",
      "Done (t=5.94s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:06<00:00, 204.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1480/1480 [00:07<00:00, 208.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1117/1117 [00:10<00:00, 105.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # from coco_custom import COCO_loader\n",
    "\n",
    "# categories = [\"bus\", \"cat\", \"pizza\"]\n",
    "\n",
    "# train_cl = COCO_loader()\n",
    "# for category in categories:\n",
    "#     train_cl.save_images_to_folder(category)\n",
    "#     with open(f'./train_manifest_{category}.pkl', 'rb') as handle:\n",
    "#         data = pickle.load(handle)\n",
    "\n",
    "#     print(len(data))\n",
    "\n",
    "# val_cl = COCO_loader(dataType='val')\n",
    "# for category in categories:\n",
    "#     val_cl.save_images_to_folder(category)\n",
    "#     with open(f'./val_manifest_{category}.pkl', 'rb') as handle:\n",
    "#         data = pickle.load(handle)\n",
    "\n",
    "#     print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "categories = [\"bus\", \"cat\", \"pizza\"]\n",
    "\n",
    "train_dataset = MyDataset(categories=categories, split=\"train\")\n",
    "val_dataset = MyDataset(categories=categories, split=\"val\")\n",
    "\n",
    "\n",
    "num_images = 3\n",
    "for data_split in [\"train\", \"val\"]:\n",
    "    all_images = []\n",
    "    for category in categories:\n",
    "\n",
    "        split_path = f\"./{data_split}_manifest_{category}.pkl\"\n",
    "        with open(split_path, \"rb\") as handle:\n",
    "            data = pickle.load(handle)\n",
    "        # print(category, data_split)\n",
    "        # path = os.path.join(data_path, category, data_split)\n",
    "        # path = os.path.join(path, category)\n",
    "        # image_list = os.listdir(path)[:num_images]\n",
    "        # print(image_list)\n",
    "        cat_images = []\n",
    "        for d in data[:num_images]:\n",
    "            x, y, w, h = d[\"bboxes\"][0]\n",
    "            img = cv2.imread(d[\"file_name\"])\n",
    "            img = cv2.rectangle(\n",
    "                img, (x, y), (x + w, y + h), color=(36, 255, 0), thickness=2\n",
    "            )\n",
    "            img = cv2.putText(\n",
    "                img,\n",
    "                org=(x, y - 10),\n",
    "                text=d[\"category\"],\n",
    "                color=(255, 0, 0),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=0.8,\n",
    "                thickness=2,\n",
    "            )\n",
    "            cat_images.append(img)\n",
    "        tot_images = np.concatenate(cat_images, axis=1)\n",
    "\n",
    "        all_images.append(tot_images)\n",
    "\n",
    "    all_images = np.concatenate(all_images, axis=0)\n",
    "\n",
    "    cv2.imwrite(f\"./{data_split}_sampled_images.png\", all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 2, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m                     torch\u001b[39m.\u001b[39msave(net\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mresults/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m net_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m                 running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 96\u001b[0m train(skip_block, train_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[28], line 76\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_dataloader, epochs, net_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     75\u001b[0m \u001b[39m# print(outputs)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     77\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     78\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/mnt/cloudNAS4/akshita/anaconda3/envs/ece60146/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/cloudNAS4/akshita/anaconda3/envs/ece60146/lib/python3.8/site-packages/torch/nn/modules/loss.py:1150\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1150\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1151\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1152\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/mnt/cloudNAS4/akshita/anaconda3/envs/ece60146/lib/python3.8/site-packages/torch/nn/functional.py:2846\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2845\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2846\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MySkipBlock(nn.Module):\n",
    "            def __init__(self, in_ch, out_ch, downsample=False, skip_connections=True):\n",
    "                super(MySkipBlock, self).__init__()\n",
    "\n",
    "                # since it only works for out_ch are same or double as in_ch \n",
    "                assert out_ch == in_ch or out_ch == 2*in_ch\n",
    "\n",
    "                self.downsample = downsample\n",
    "                self.skip_connections = skip_connections\n",
    "                self.in_ch = in_ch\n",
    "                self.out_ch = out_ch\n",
    "\n",
    "                self.convo1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "                self.convo2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1)\n",
    "                norm_layer1 = nn.BatchNorm2d\n",
    "                norm_layer2 = nn.BatchNorm2d\n",
    "                self.bn1 = norm_layer1(out_ch)\n",
    "                self.bn2 = norm_layer2(out_ch)\n",
    "                if downsample:\n",
    "                    self.downsampler = nn.Conv2d(in_ch, out_ch, 1, stride=2)\n",
    "\n",
    "            def forward(self, x):\n",
    "                identity = x                                     \n",
    "                out = self.convo1(x)                              \n",
    "                out = self.bn1(out)                              \n",
    "                out = torch.nn.functional.relu(out)\n",
    "\n",
    "                out = self.convo2(out)                              \n",
    "                out = self.bn2(out)                              \n",
    "                out = torch.nn.functional.relu(out)\n",
    "\n",
    "                if self.downsample:\n",
    "                    out = self.downsampler(out)\n",
    "                    identity = self.downsampler(identity)\n",
    "                \n",
    "                if self.skip_connections:\n",
    "                    if self.in_ch == self.out_ch:\n",
    "                        out += identity                              \n",
    "                    else:\n",
    "                        # out[:,:self.in_ch,:,:] += identity\n",
    "                        # out[:,self.in_ch:,:,:] += identity\n",
    "                        torch.cat((out[:, :self.in_ch, :, :] + identity, out[:, self.in_ch:, :, :] + identity), dim=1)\n",
    "                return out\n",
    "            \n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The acronym 'LOAD' stands for 'LOcalization And Detection'.\n",
    "    LOADnet2 uses both convo and linear layers for regression\n",
    "\n",
    "    Class Path:   DLStudio  ->  DetectAndLocalize  ->  LOADnet2\n",
    "    \"\"\" \n",
    "    def __init__(self, skip_connections=True, depth=8):\n",
    "        super(MyNet, self).__init__()\n",
    "\n",
    "        self.depth = depth // 2\n",
    "        self.conv = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1  = nn.BatchNorm2d(64)\n",
    "        self.bn2  = nn.BatchNorm2d(128)\n",
    "        self.skip64_arr = nn.ModuleList()\n",
    "        for i in range(self.depth):\n",
    "            self.skip64_arr.append(MySkipBlock(64, 64,\n",
    "                                                    skip_connections=skip_connections))\n",
    "        self.skip64ds = DLStudio.DetectAndLocalize.SkipBlock(64, 64, \n",
    "                                    downsample=True, skip_connections=skip_connections)\n",
    "        self.skip64to128 = DLStudio.DetectAndLocalize.SkipBlock(64, 128, \n",
    "                                                    skip_connections=skip_connections )\n",
    "        self.skip128_arr = nn.ModuleList()\n",
    "        for i in range(self.depth):\n",
    "            self.skip128_arr.append(DLStudio.DetectAndLocalize.SkipBlock(128, 128,\n",
    "                                                    skip_connections=skip_connections))\n",
    "        self.skip128ds = DLStudio.DetectAndLocalize.SkipBlock(128,128,\n",
    "                                    downsample=True, skip_connections=skip_connections)\n",
    "        self.fc1 =  nn.Linear(2048, 1000)\n",
    "        self.fc2 =  nn.Linear(1000, 5)\n",
    "\n",
    "        ##  for regression\n",
    "        self.conv_seqn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc_seqn = nn.Sequential(\n",
    "            nn.Linear(16384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4)        ## output for the 4 coords (x_min,y_min,x_max,y_max) of BBox\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.MaxPool2d(2,2)(torch.nn.functional.relu(self.conv(x)))          \n",
    "        ## The labeling section:\n",
    "        x1 = x.clone()\n",
    "        for i,skip64 in enumerate(self.skip64_arr[:self.depth//4]):\n",
    "            x1 = skip64(x1)                \n",
    "        x1 = self.skip64ds(x1)\n",
    "        for i,skip64 in enumerate(self.skip64_arr[self.depth//4:]):\n",
    "            x1 = skip64(x1)                \n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.skip64to128(x1)\n",
    "        for i,skip128 in enumerate(self.skip128_arr[:self.depth//4]):\n",
    "            x1 = skip128(x1)                \n",
    "        x1 = self.bn2(x1)\n",
    "        x1 = self.skip128ds(x1)\n",
    "        for i,skip128 in enumerate(self.skip128_arr[self.depth//4:]):\n",
    "            x1 = skip128(x1)                \n",
    "        x1 = x1.view(-1, 2048 )\n",
    "        x1 = torch.nn.functional.relu(self.fc1(x1))\n",
    "        x1 = self.fc2(x1)\n",
    "        ## The Bounding Box regression:\n",
    "        x2 = self.conv_seqn(x)\n",
    "        # flatten\n",
    "        x2 = x2.view(x.size(0), -1)\n",
    "        x2 = self.fc_seqn(x2)\n",
    "        return x1,x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1734, 0.1523, 0.0170]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.0287, -0.0136,  0.0113,  0.0064]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, \n",
    "                 out_channels, \n",
    "                 stride = 1, \n",
    "                 downsample = None):\n",
    "        \n",
    "        '''\n",
    "        in_channels: input channels, \n",
    "        out_channels: output channels, \n",
    "        downsample: set to None but modified based on stride and out channels\n",
    "        '''\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = None\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, \n",
    "                                  kernel_size = 3, \n",
    "                                  stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, 1, stride=2)\n",
    "        \n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        else:\n",
    "            if self.in_channels != self.out_channels:\n",
    "                out = torch.cat((out[:, :self.in_channels, :, :] + residual, \n",
    "                        out[:, self.in_channels:, :, :] + residual), dim=1)\n",
    "                return self.relu(out)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class HW5Net(nn.Module):\n",
    "    def __init__(self, in_ch, \n",
    "                #  out_ch, \n",
    "                 ngf=8, \n",
    "                 n_downsample=2, \n",
    "                 n_blocks=4) -> None:\n",
    "        super(HW5Net, self).__init__()\n",
    "        model_layers = [nn.ReflectionPad2d(3) ,\n",
    "                    nn.Conv2d(in_ch, \n",
    "                              ngf, \n",
    "                              kernel_size =7, \n",
    "                              padding=0),\n",
    "                    nn.BatchNorm2d(ngf) ,\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        for i in range(n_downsample):\n",
    "            mult = 2**i\n",
    "            model_layers += [nn.Conv2d(ngf*mult, ngf*mult*2, kernel_size=3, \n",
    "                                padding=1, stride=2), \n",
    "                        nn.BatchNorm2d(ngf*mult*2),\n",
    "                        nn.ReLU(True)]\n",
    "        \n",
    "        mult = 2**n_downsample\n",
    "        # for i in range(n_blocks):\n",
    "        model_layers += [ResnetBlock(ngf*mult, ngf*mult*2, stride=1, downsample=False)]\n",
    "        mult *= 2\n",
    "        for _ in range(n_blocks - 1):\n",
    "            model_layers += [ResnetBlock(ngf*mult, ngf*mult*2, stride=2, downsample=True)]\n",
    "            mult *=2\n",
    "\n",
    "        self.model = nn.Sequential(*model_layers)\n",
    "\n",
    "        classification_head = [nn.Linear(2048*2*2, 1024),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(1024, 3)]\n",
    "        self.class_head = nn.Sequential(*classification_head)\n",
    "        \n",
    "\n",
    "        #  for regression\n",
    "        self.bbox_head_conv = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)])\n",
    "        \n",
    "        self.bbox_head_seq =  nn.Sequential(*[\n",
    "            nn.Linear(512*2*2, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 4)        ## output for the 4 coords (x_min,y_min,x_max,y_max) of BBox\n",
    "        ])\n",
    "        \n",
    "        # self.bbox_head = nn.Sequential(*bbox_head)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ft = self.model(x)\n",
    "        # print(ft.shape)\n",
    "        class_out = self.class_head(ft.view(1, -1))\n",
    "        # print(class_out)\n",
    "\n",
    "        regression_out = self.bbox_head_conv(ft)\n",
    "        # print(regression_out.shape)\n",
    "        regression_out = self.bbox_head_seq(regression_out.view(1, -1))\n",
    "        # print(regression_out)\n",
    "\n",
    "        return class_out, regression_out\n",
    "\n",
    "# model = HW5Net(3, 5)\n",
    "# sample = torch.rand((3, 256, 256))\n",
    "\n",
    "# model(sample.unsqueeze(0))\n",
    "# sample.shape\n",
    "\n",
    "# import torchinfo\n",
    "\n",
    "# torchinfo.summary(model, (3, 256, 256), batch_dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(\n",
    "    net, train_dataloader, epochs=10, net_name=\"net_name\"\n",
    ") -> None:\n",
    "    device = \"cuda\" if torch.cuda.is_available() == True else \"cpu\"\n",
    "    net.train()\n",
    "    net = net.to(device=device)\n",
    "\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "    criterion_MSE = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "    # tot_loss = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "        loss_flag = 1e32\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels, bbox = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            bbox = bbox.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_labels, output_bboxes = net(inputs)\n",
    "            loss_CE = criterion_CE(output_labels, labels)\n",
    "            loss_CE.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 100 == 0:\n",
    "                # opening the csv file in 'w+' mode\n",
    "                # print(\"[epoch]: %d, batch: %5d] loss: %.3f\" %(epoch+1, i+1, running_loss / 100))\n",
    "                data = [epoch + 1, i + 1, running_loss / 100]\n",
    "                file = open(\"results/\" + net_name + \".csv\", \"a\", newline=\"\")\n",
    "                # writing the data into the file\n",
    "                with file:\n",
    "                    write = csv.writer(file)\n",
    "                    write.writerow(data)\n",
    "\n",
    "                # tot_loss.append(running_loss/100)\n",
    "                if running_loss < loss_flag:\n",
    "                    loss_flag = running_loss\n",
    "                    torch.save(net.state_dict(), \"results/\" + net_name + \".pt\")\n",
    "                running_loss = 0.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f680f4d97cf514679e00d4da1d9b5ffad508e5bcade52d18cdbe0b82edcbe4b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
