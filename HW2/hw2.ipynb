{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tvt\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from time import time\n",
    "\n",
    "\n",
    "# img1 = Image.open('data/front.jpg')\n",
    "# img2 = Image.open('data/oblique.jpg')\n",
    "\n",
    "img1 = Image.open('three.jpg')\n",
    "img2 = Image.open('two.jpg')\n",
    "affine_tr = tvt.RandomAffine((50, 60))\n",
    "img1 = affine_tr(img1)\n",
    "# display(img1)\n",
    "\n",
    "# replace the following with new points\n",
    "two = [[623, 589], [653, 1193], [958, 1143], [928, 722]]\n",
    "three = [[440, 691], [453, 1234], [1088, 1229], [1094, 691]]\n",
    "\n",
    "transformed_image = tvt.functional.perspective(img2, startpoints=two, endpoints=three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(img):\n",
    "    tensor_img = tvt.functional.pil_to_tensor(img).float()\n",
    "    hist_img = torch.histc(tensor_img, bins=10, min=0, max=255)\n",
    "    hist_img = hist_img.div(hist_img.sum())\n",
    "    return hist_img\n",
    "\n",
    "hist_img1 = get_hist(img1)\n",
    "hist_img2 = get_hist(transformed_image)# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "dist = wasserstein_distance(hist_img1.cpu().numpy(), \n",
    "                            hist_img2.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([3, 256, 256]) 9\n"
     ]
    }
   ],
   "source": [
    "from mydataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "my_dataset = MyDataset('data')\n",
    "print(len(my_dataset))\n",
    "index = 9\n",
    "print(my_dataset[index][0].shape, my_dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.25428366661072\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "num_tot_images = len(my_dataset)\n",
    "for i in range(1000):\n",
    "    my_dataset.__getitem__(i%num_tot_images)\n",
    "\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.23933792114258\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "start = time()\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    for img, labels in train_dataloader:\n",
    "        count += labels.shape[0]\n",
    "    if count >=1000:\n",
    "        break\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.33969831466675\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    for img, labels in train_dataloader:\n",
    "        count += labels.shape[0]\n",
    "    if count >=1000:\n",
    "        break\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label) in enumerate(train_dataloader):\n",
    "    print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze().transpose(0, 1).transpose(1, 2)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "ece60146"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ae1c7a0ea8ba8f965de3a6463436fb89ce56e137873376e122f5b001a1fe97c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
