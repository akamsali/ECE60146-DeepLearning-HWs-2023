{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "creating basic encoder...\n",
      "creating self attention layer...\n",
      "creating basic encoder...\n",
      "creating self attention layer...\n",
      "creating self attention layer...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchsummary\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "# master_encoder = MasterEncoder(max_seq_length=17, embedding_size=8, how_many_basic_encoders=1, num_atten_heads=2)\n",
    "# # test = torch.rand(1, 17, 16*16*3)\n",
    "# encoder = BasicEncoder(max_seq_length=17, embedding_size=2*2*3, num_atten_heads=1)\n",
    "# self_attn = SelfAttention(max_seq_length=17, embedding_size=2*2*3, num_atten_heads=3)\n",
    "# attn_head = AttentionHead(max_seq_length=17, qkv_size=2*2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1                [-1, 17, 8]              16\n",
      "            Linear-2                   [-1, 68]           4,692\n",
      "            Linear-3                   [-1, 68]           4,692\n",
      "            Linear-4                   [-1, 68]           4,692\n",
      "           Softmax-5               [-1, 17, 17]               0\n",
      "     AttentionHead-6                [-1, 17, 4]               0\n",
      "            Linear-7                   [-1, 68]           4,692\n",
      "            Linear-8                   [-1, 68]           4,692\n",
      "            Linear-9                   [-1, 68]           4,692\n",
      "          Softmax-10               [-1, 17, 17]               0\n",
      "    AttentionHead-11                [-1, 17, 4]               0\n",
      "    SelfAttention-12                [-1, 17, 8]               0\n",
      "        LayerNorm-13                [-1, 17, 8]              16\n",
      "           Linear-14                  [-1, 272]          37,264\n",
      "           Linear-15                  [-1, 136]          37,128\n",
      "     BasicEncoder-16                [-1, 17, 8]               0\n",
      "================================================================\n",
      "Total params: 102,576\n",
      "Trainable params: 102,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.41\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(torchsummary.summary(attn_head, (17, 2*2*3)))\n",
    "# print(torchsummary.summary(self_attn, (17, 2*2*3)))\n",
    "# print(torchsummary.summary(encoder, (17, 2*2*3)))\n",
    "# print(torchsummary.summary(master_encoder, ( 17, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Finished Training Epoch 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "(2500,) (2500,)\n",
      "[[353  86  16  17  28]\n",
      " [ 56 310  32  49  53]\n",
      " [ 37  80 134  71 178]\n",
      " [ 66 120  74  74 166]\n",
      " [  7  33  42  14 404]]\n",
      "[[353  86  16  17  28]\n",
      " [ 56 310  32  49  53]\n",
      " [ 37  80 134  71 178]\n",
      " [ 66 120  74  74 166]\n",
      " [  7  33  42  14 404]] <function accuracy_score at 0x7fb0a4514c10>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vit_embeddings.load_state_dict(\n",
    "    torch.load(\"test_epoch_1.pth\", map_location=torch.device(\"cpu\"))\n",
    ")\n",
    "cm, acc = test(vit_embeddings, val_loader, name=\"test\")\n",
    "print(cm, acc)\n",
    "\n",
    "\n",
    "# def validation(net, val_dataset) -> Union[list, list]:\n",
    "#     true_labels = []\n",
    "#     pred_labels = []\n",
    "#     net.eval()\n",
    "#     for i in range(len(val_dataset)):\n",
    "#         img, label = val_dataset.__getitem__(i)\n",
    "#         # print(img.shape)\n",
    "#         true_labels.append(label)\n",
    "#         output = net(img.unsqueeze(0))\n",
    "#         output = F.softmax(output, dim=1)\n",
    "#         output = torch.argmax(output)\n",
    "#         pred_labels.append(output.item())\n",
    "#         # break\n",
    "#     return true_labels, pred_labels\n",
    "\n",
    "\n",
    "# def validate_and_conf_matrix(net, val_dataset, categories, name=\"Net\") -> None:\n",
    "#     t, p = validation(net, val_dataset=val_dataset)\n",
    "#     cm = confusion_matrix(t, p)\n",
    "#     plt.figure()\n",
    "#     sns.heatmap(cm, annot=cm, xticklabels=categories, yticklabels=categories, fmt=\"g\")\n",
    "#     plt.title(f\"Confusion matrix for {name}, accuracy={accuracy_score(t, p)}\")\n",
    "#     plt.xlabel(\"Predicted labels\")\n",
    "#     plt.ylabel(\"True labels\")\n",
    "#     plt.savefig(f\"results/cm_{name}.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
