{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from utils import weights_init\n",
    "import model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_wgan(train_loader, \n",
    "                noise_dim=100, \n",
    "                batch_size=4, \n",
    "                device=torch.device(\"cpu\"), \n",
    "                lr=0.0002, \n",
    "                betas=(0.5, 0.999), \n",
    "                epochs=1,\n",
    "                clipping_thresh = 0.01,\n",
    "                name=\"wgan\"):\n",
    "\n",
    "    netC = model.CriticCG1().to(device)\n",
    "    netG = model.Generator().to(device)\n",
    "    netC.apply(weights_init)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    fixed_noise = torch.randn(batch_size, noise_dim, 1, 1, device=device)\n",
    "    # instead of real and fake labels, we use 1 and -1\n",
    "    one = torch.FloatTensor([1]).to(device)\n",
    "    minus_one = torch.FloatTensor([-1]).to(device)\n",
    "    # real_label = 1\n",
    "    # fake_label = 0\n",
    "\n",
    "    optimizerC = torch.optim.Adam(netC.parameters(), lr=lr, betas=betas)\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    C_losses = []\n",
    "    G_losses = []                               \n",
    "    img_list = []\n",
    "    iters = 0\n",
    "    gen_iterations = 0   \n",
    "    loss_G_flag = 100000\n",
    "    loss_D_flag = 100000\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(len(train_loader))\n",
    "        data_iterator = iter(train_loader)\n",
    "        i = 0\n",
    "        n_critic = 5\n",
    "        \n",
    "        while i < len(train_loader):\n",
    "            print(i)\n",
    "            for param in netC.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "                n_critic = 100\n",
    "            \n",
    "            print(\"entering loop: \", n_critic, gen_iterations)\n",
    "            # while ic < n_critic and i < len(train_loader):\n",
    "            for _ in tqdm(range(n_critic)):\n",
    "                if i >= len(train_loader):\n",
    "                    break\n",
    "\n",
    "                for p in netC.parameters():\n",
    "                    p.data.clamp_(-clipping_thresh, clipping_thresh)\n",
    "                \n",
    "                netC.zero_grad()\n",
    "                real_images = data_iterator.next().to(device)\n",
    "                \n",
    "                b_size = real_images.size(0)\n",
    "\n",
    "                critic_for_real = netC(real_images)\n",
    "                critic_for_real.backward(minus_one)\n",
    "\n",
    "                noise = torch.randn(b_size, noise_dim, 1, 1, device=device)\n",
    "                fake = netG(noise)\n",
    "                critic_for_fake = netC(fake)\n",
    "                critic_for_fake.backward(one)\n",
    "\n",
    "                wasserstein_distance = critic_for_real - critic_for_fake\n",
    "                critic_loss = critic_for_fake - critic_for_real\n",
    "\n",
    "                optimizerC.step()\n",
    "                i += 1\n",
    "\n",
    "            \n",
    "            # now we come to generator, for which we don't need to update critic\n",
    "            # so we freeze the critic parameters\n",
    "            for p in netC.parameters():\n",
    "                p.requires_grad = False\n",
    "            # we need to update generator\n",
    "            print(\"entering generator\")\n",
    "            netG.zero_grad()\n",
    "            noise = torch.randn(b_size, noise_dim, 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            critic_for_fake = netC(fake)\n",
    "            gen_loss = critic_for_fake\n",
    "            critic_for_fake.backward(minus_one)\n",
    "\n",
    "            # update generator\n",
    "            optimizerG.step()\n",
    "            gen_iterations += 1\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                save_vals = [epoch, epochs, i, len(train_loader), \n",
    "                             critic_loss.data[0].item(), gen_loss.data[0].item(),\n",
    "                             wasserstein_distance.data[0].item()]\n",
    "\n",
    "                logger = open(f\"./solutions/{name}.csv\", \"a\", newline=\"\")\n",
    "                with logger:\n",
    "                    write = csv.writer(logger)\n",
    "                    write.writerow(save_vals)\n",
    "\n",
    "                if gen_loss.data[0].item() < loss_G_flag:\n",
    "                    loss_G_flag = gen_loss.data[0].item()\n",
    "                    torch.save(netG.state_dict(), \"./solutions/gen_\" + name + \".pt\")\n",
    "                if critic_loss.data[0].item() < loss_D_flag:\n",
    "                    loss_D_flag = critic_loss.data[0].item()\n",
    "                    torch.save(netC.state_dict(), \"./solutions/critic_\" + name + \".pt\")\n",
    "\n",
    "                # running_D_loss = 0.0\n",
    "                # running_G_loss = 0.0\n",
    "\n",
    "            C_losses.append(critic_loss.data[0].item())\n",
    "            G_losses.append(gen_loss.data[0].item())\n",
    "            if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(train_loader)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = netG(fixed_noise).detach().cpu()\n",
    "                img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))\n",
    "            iters += 1\n",
    "\n",
    "        \n",
    "    with open(f\"./solutions/{name}_C_loss.pkl\", \"wb\") as logger:\n",
    "        pickle.dump(C_losses, logger)\n",
    "    logger.close()\n",
    "    with open(f\"./solutions/{name}_G_loss.pkl\", \"wb\") as logger:\n",
    "        pickle.dump(G_losses, logger)\n",
    "    logger.close()\n",
    "    with open(f\"./solutions/{name}_img_list.pkl\", \"wb\") as logger:\n",
    "        pickle.dump(img_list, logger)\n",
    "    logger.close()\n",
    "\n",
    "from dataloader import MyDataset\n",
    "# from train import train_gan\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "data_path = '/home/akshita/Documents/data/pizzas'\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(data_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_wgan(train_loader, epochs=1, name=\"wgan\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "from model import Generator, CriticCG1\n",
    "import torch\n",
    "\n",
    "# netG = Generator()\n",
    "netD = CriticCG1()\n",
    "# torchsummary.summary(netG, (100, 1, 1))\n",
    "# torchsummary.summary(netD, (3, 64, 64))\n",
    "# sample = torch.randn(1, 3, 64, 64)\n",
    "# out = netD(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import torchvision.transforms.functional as tvtF\n",
    "# import imageio   \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# # Load the data\n",
    "# with open('./solutions/gan_D_loss.pkl', 'rb') as f:\n",
    "#     d_data = pickle.load(f)\n",
    "\n",
    "# with open('./solutions/gan_G_loss.pkl', 'rb') as f:\n",
    "#     g_data = pickle.load(f)\n",
    "\n",
    "# plt.plot(d_data, label='Discriminator')\n",
    "# plt.plot(g_data, label='Generator')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "with open('./solutions/fake_data.pkl', 'rb') as f:\n",
    "    fake_images = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./solutions/gan_img_list.pkl', 'rb') as f:\n",
    "#     img_data = pickle.load(f)\n",
    "# images = []           \n",
    "# for imgobj in img_data:  \n",
    "#     img = tvtF.to_pil_image(imgobj)  \n",
    "#     images.append(img) \n",
    "# imageio.mimsave(\"./solutions/generation_animation.gif\", images, fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import MyDataset\n",
    "import model\n",
    "\n",
    "\n",
    "import torch\n",
    "from pytorch_fid.fid_score import calculate_activation_statistics, calculate_frechet_distance\n",
    "from pytorch_fid.inception import InceptionV3\n",
    "\n",
    "# Load the data\n",
    "fake_path = '/home/akshita/Documents/data/fake_pizzas'\n",
    "eval_path = '/home/akshita/Documents/data/pizzas'\n",
    "val_dataset = MyDataset(data_path=eval_path, split='eval')\n",
    "eval_image_files = val_dataset.file_list\n",
    "len(eval_image_files)\n",
    "\n",
    "# device = torch.device('cuda' if )\n",
    "# dims = 2048\n",
    "# block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "# model = InceptionV3([block_idx]).to(device)\n",
    "\n",
    "# if not os.path.exists(mac_path):\n",
    "    # os.makedirs(mac_path)\n",
    "# len(val_dataset)\n",
    "\n",
    "# Load the model\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "# generator = model.Generator()\n",
    "# generator.load_state_dict(torch.load('./solutions/gen_gan.pt', map_location=device))\n",
    "# generator.eval()\n",
    "# for i in range(1000):\n",
    "#     noise = torch.randn(1, 100, 1, 1, device=device)\n",
    "#     fake = generator(noise)\n",
    "#     fake = fake.detach().cpu().numpy()\n",
    "#     # print(fake.shape)\n",
    "#     fake = np.transpose(fake, (0, 2, 3, 1))\n",
    "#     # print(fake.shape)\n",
    "#     fake = ((fake + 1) * 127.5).astype(np.uint8)\n",
    "#     fake = fake[0]\n",
    "#     fake = np.expand_dims(fake, axis=0)\n",
    "#     if i == 0:\n",
    "#         fake_data = fake\n",
    "#     else:\n",
    "        # fake_data = np.concatenate((fake_data, fake), axis=0)\n",
    "\n",
    "# with open('./solutions/fake_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(fake_data, f)\n",
    "\n",
    "\n",
    "# for i, img in enumerate(fake_images):\n",
    "#     cv2.imwrite(os.path.join(fake_path, f\"{i}.jpg\"), img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, img in enumerate(fake_images):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(os.path.join(fake_path, f\"{i}.jpg\"), bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4ef29a076c9239734182ccf4c0f2b6b130b342c3faa23f95e08b32fb769f1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
